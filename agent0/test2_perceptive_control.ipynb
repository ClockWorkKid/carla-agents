{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d60cba9",
   "metadata": {},
   "source": [
    "# Initialize Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a63241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from myAgent import CarlaAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ae408c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establishing Connection to Server\n",
      "created vehicle.tesla.model3\n",
      "created sensor.camera.rgb\n",
      "created sensor.camera.semantic_segmentation\n",
      "deployed\n"
     ]
    }
   ],
   "source": [
    "myAgent = CarlaAgent()\n",
    "myAgent.spawn_vehicle()\n",
    "myAgent.attach_camera()\n",
    "myAgent.attach_cameraS()\n",
    "# myAgent.autopilot(20)\n",
    "myAgent.attach_controller()\n",
    "myAgent.find_vehicle()\n",
    "print(\"deployed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf5f0ae",
   "metadata": {},
   "source": [
    "# Perception Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4949ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using torch 1.8.0 CUDA:0 (GeForce RTX 3090, 24260MB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Model Initialized!\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Summary: 484 layers, 88922205 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detector Model Initialized!\n"
     ]
    }
   ],
   "source": [
    "from perception.tools.ddrnetSegmentation import DDRNet\n",
    "from perception.tools.yoloDetector import Yolo\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "segmenter = DDRNet()\n",
    "detector = Yolo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a94314f",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c7826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo driving test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahsay/anaconda3/envs/agent0/lib/python3.7/site-packages/torch/nn/functional.py:3455: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "sim_time = 120\n",
    "\n",
    "print(\"Demo driving test\")\n",
    "\n",
    "# Drive straight\n",
    "# myAgent.control.throttle = 0\n",
    "# myAgent.control.brake = 0\n",
    "# myAgent.control.steer = 0\n",
    "# myAgent.control.hand_brake = 0\n",
    "# myAgent.control.reverse = 0\n",
    "\n",
    "# myAgent.vehicle.apply_control(myAgent.control)\n",
    "\n",
    "\n",
    "IMAGE_H, IMAGE_W, _ = myAgent.image.shape\n",
    "src = np.float32([[0, IMAGE_H], [IMAGE_W, IMAGE_H],\n",
    "                  [int(2*IMAGE_W/5), int(IMAGE_H/2)], [int(3*IMAGE_W/5), int(IMAGE_H/2)]])\n",
    "dst = np.float32([[300, IMAGE_H], [500, IMAGE_H], [300, 0], [500, 0]])\n",
    "M = cv2.getPerspectiveTransform(src, dst) # The transformation matrix\n",
    "\n",
    "h = int(IMAGE_H/2)\n",
    "w = int(IMAGE_W/2)\n",
    "    \n",
    "myAgent.vehicle.set_autopilot(True)\n",
    "\n",
    "t = time.time()\n",
    "while(time.time()-t < sim_time):\n",
    "    \n",
    "    road_class = 7\n",
    "    RGB = np.copy(myAgent.image)\n",
    "    sem = np.copy(myAgent.imageS[:,:,2])\n",
    "    sem[sem!=road_class] = 0\n",
    "    sem[sem==road_class] = 255\n",
    "    \n",
    "    segmented_image = segmenter.segments(RGB)\n",
    "    \n",
    "    threshold = 4\n",
    "    segseg = segmented_image[0].cpu().detach().numpy()\n",
    "    segseg = np.copy(segseg[0, :, :, :])\n",
    "    segseg = segseg.transpose((1, 2, 0))\n",
    "    segseg = segseg[:, :, 0]\n",
    "#     segseg[segseg<=threshold] = 0\n",
    "#     segseg[segseg>threshold] = 255\n",
    "    \n",
    "    detected_image = detector.detect(RGB)\n",
    "\n",
    "    warped_RGB = cv2.warpPerspective(RGB, M, (IMAGE_W, IMAGE_H)) # Image warping\n",
    "    warped_sem = cv2.warpPerspective(sem, M, (IMAGE_W, IMAGE_H)) # Image warping\n",
    "    \n",
    "    moment = cv2.moments(warped_sem[int(IMAGE_H/2):,int(IMAGE_W/4):int(3*IMAGE_W/4)])\n",
    "    # calculate x,y coordinate of center\n",
    "    try:\n",
    "        cX = int(moment[\"m10\"] / moment[\"m00\"])+int(IMAGE_W/4)\n",
    "        cY = int(moment[\"m01\"] / moment[\"m00\"])+int(IMAGE_H/4)\n",
    "    except:\n",
    "        cX = int(IMAGE_W/2)\n",
    "        cY = int(IMAGE_H/2)\n",
    "    # put text and highlight the center\n",
    "    cv2.circle(warped_RGB, (cX, cY), 20, (0, 0, 255), -1)\n",
    "    cv2.putText(warped_RGB, \"centroid\", (cX - 25, cY - 25),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "    \n",
    "#     myAgent.control.steer = (cX-IMAGE_W/2)/(IMAGE_W)\n",
    "#     myAgent.vehicle.apply_control(myAgent.control)\n",
    "\n",
    "    \n",
    "    cv2.imshow('Original Frame', cv2.resize(RGB, (w, h)))\n",
    "    cv2.imshow('Original Warped', cv2.resize(warped_RGB, (w, h)))\n",
    "    cv2.imshow('Segmentation Frame', cv2.resize(sem, (w, h)))\n",
    "    cv2.imshow('Segmentation Warped', cv2.resize(warped_sem, (w, h)))\n",
    "    cv2.imshow('Inferred Segmentation', cv2.resize(segseg, (w, h)))\n",
    "    cv2.imshow('Object Detection', cv2.resize(detected_image, (w, h)))    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "myAgent.vehicle.set_autopilot(False)\n",
    "# Stop\n",
    "# myAgent.control.throttle = 0\n",
    "# myAgent.control.brake = 0\n",
    "# myAgent.control.steer = 0\n",
    "# myAgent.control.hand_brake = 1\n",
    "# myAgent.control.reverse = 0\n",
    "# myAgent.vehicle.apply_control(myAgent.control)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4d7759",
   "metadata": {},
   "source": [
    "### Reverse Gear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4ce6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "myAgent.control.throttle = 0.5\n",
    "myAgent.control.brake = 0\n",
    "myAgent.control.steer = 0\n",
    "myAgent.control.hand_brake = 0\n",
    "myAgent.control.reverse = 1\n",
    "\n",
    "myAgent.vehicle.apply_control(myAgent.control)\n",
    "\n",
    "\n",
    "t = time.time()\n",
    "while(time.time()-t < 5):\n",
    "    None\n",
    "    \n",
    "myAgent.control.throttle = 0\n",
    "myAgent.control.brake = 0\n",
    "myAgent.control.steer = 0\n",
    "myAgent.control.hand_brake = 1\n",
    "myAgent.control.reverse = 0\n",
    "\n",
    "myAgent.vehicle.apply_control(myAgent.control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7b0f93",
   "metadata": {},
   "source": [
    "# Terminate Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24426dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "destroying actors\n",
      "terminated\n"
     ]
    }
   ],
   "source": [
    "myAgent.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
